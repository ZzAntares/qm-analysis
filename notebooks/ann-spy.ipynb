{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting direction of stock price index movement using artificial neural networks\n",
    "### Por Yakup Kara, Melek Acar Boyacioglu y Omer Kaan Baykan\n",
    "#### Replicación del estudio por Julio Gutiérrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the daily data for Istambul Stock Exchange National Index 100 couldn't be found, the study is replicated with the SP&5000 daily data from 2007 to 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "      <td>256.600006</td>\n",
       "      <td>256.829987</td>\n",
       "      <td>256.149994</td>\n",
       "      <td>256.559998</td>\n",
       "      <td>256.559998</td>\n",
       "      <td>66935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-25</th>\n",
       "      <td>256.179993</td>\n",
       "      <td>256.309998</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>255.289993</td>\n",
       "      <td>255.289993</td>\n",
       "      <td>103715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-26</th>\n",
       "      <td>255.990005</td>\n",
       "      <td>256.299988</td>\n",
       "      <td>255.479996</td>\n",
       "      <td>255.619995</td>\n",
       "      <td>255.619995</td>\n",
       "      <td>69798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-27</th>\n",
       "      <td>256.470001</td>\n",
       "      <td>257.890015</td>\n",
       "      <td>255.630005</td>\n",
       "      <td>257.709991</td>\n",
       "      <td>257.709991</td>\n",
       "      <td>85562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>256.470001</td>\n",
       "      <td>257.600006</td>\n",
       "      <td>256.410004</td>\n",
       "      <td>256.750000</td>\n",
       "      <td>256.750000</td>\n",
       "      <td>53199200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "Date                                                                     \n",
       "2017-10-24  256.600006  256.829987  256.149994  256.559998  256.559998   \n",
       "2017-10-25  256.179993  256.309998  254.000000  255.289993  255.289993   \n",
       "2017-10-26  255.990005  256.299988  255.479996  255.619995  255.619995   \n",
       "2017-10-27  256.470001  257.890015  255.630005  257.709991  257.709991   \n",
       "2017-10-30  256.470001  257.600006  256.410004  256.750000  256.750000   \n",
       "\n",
       "               volume  \n",
       "Date                   \n",
       "2017-10-24   66935900  \n",
       "2017-10-25  103715300  \n",
       "2017-10-26   69798000  \n",
       "2017-10-27   85562500  \n",
       "2017-10-30   53199200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy = pd.read_csv('data/SPY10.csv', index_col='Date', parse_dates=True)\n",
    "spy.columns = ['open', 'high', 'low', 'close', 'adjclose', 'volume']\n",
    "spy.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The direction of daily change in the S&P500 is categorized as `0` or `1`. If the S&P500 Index at time `t` is higher than that at time `t-1`, direction `t` is `1`. If the S&P500 Index at time `t` is lower than that at time `t-1`, direction `t` is `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>prior_close</th>\n",
       "      <th>direction</th>\n",
       "      <th>future_direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-16</th>\n",
       "      <td>255.210007</td>\n",
       "      <td>255.509995</td>\n",
       "      <td>254.820007</td>\n",
       "      <td>255.289993</td>\n",
       "      <td>255.289993</td>\n",
       "      <td>38221700</td>\n",
       "      <td>254.949997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-17</th>\n",
       "      <td>255.229996</td>\n",
       "      <td>255.520004</td>\n",
       "      <td>254.979996</td>\n",
       "      <td>255.470001</td>\n",
       "      <td>255.470001</td>\n",
       "      <td>31561000</td>\n",
       "      <td>255.289993</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-18</th>\n",
       "      <td>255.899994</td>\n",
       "      <td>255.949997</td>\n",
       "      <td>255.500000</td>\n",
       "      <td>255.720001</td>\n",
       "      <td>255.720001</td>\n",
       "      <td>40888300</td>\n",
       "      <td>255.470001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19</th>\n",
       "      <td>254.830002</td>\n",
       "      <td>255.830002</td>\n",
       "      <td>254.350006</td>\n",
       "      <td>255.789993</td>\n",
       "      <td>255.789993</td>\n",
       "      <td>61903800</td>\n",
       "      <td>255.720001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-20</th>\n",
       "      <td>256.700012</td>\n",
       "      <td>257.140015</td>\n",
       "      <td>255.770004</td>\n",
       "      <td>257.109985</td>\n",
       "      <td>257.109985</td>\n",
       "      <td>89176400</td>\n",
       "      <td>255.789993</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>257.480011</td>\n",
       "      <td>257.510010</td>\n",
       "      <td>256.019989</td>\n",
       "      <td>256.109985</td>\n",
       "      <td>256.109985</td>\n",
       "      <td>63915300</td>\n",
       "      <td>257.109985</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "      <td>256.600006</td>\n",
       "      <td>256.829987</td>\n",
       "      <td>256.149994</td>\n",
       "      <td>256.559998</td>\n",
       "      <td>256.559998</td>\n",
       "      <td>66935900</td>\n",
       "      <td>256.109985</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-25</th>\n",
       "      <td>256.179993</td>\n",
       "      <td>256.309998</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>255.289993</td>\n",
       "      <td>255.289993</td>\n",
       "      <td>103715300</td>\n",
       "      <td>256.559998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-26</th>\n",
       "      <td>255.990005</td>\n",
       "      <td>256.299988</td>\n",
       "      <td>255.479996</td>\n",
       "      <td>255.619995</td>\n",
       "      <td>255.619995</td>\n",
       "      <td>69798000</td>\n",
       "      <td>255.289993</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-27</th>\n",
       "      <td>256.470001</td>\n",
       "      <td>257.890015</td>\n",
       "      <td>255.630005</td>\n",
       "      <td>257.709991</td>\n",
       "      <td>257.709991</td>\n",
       "      <td>85562500</td>\n",
       "      <td>255.619995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "Date                                                                     \n",
       "2017-10-16  255.210007  255.509995  254.820007  255.289993  255.289993   \n",
       "2017-10-17  255.229996  255.520004  254.979996  255.470001  255.470001   \n",
       "2017-10-18  255.899994  255.949997  255.500000  255.720001  255.720001   \n",
       "2017-10-19  254.830002  255.830002  254.350006  255.789993  255.789993   \n",
       "2017-10-20  256.700012  257.140015  255.770004  257.109985  257.109985   \n",
       "2017-10-23  257.480011  257.510010  256.019989  256.109985  256.109985   \n",
       "2017-10-24  256.600006  256.829987  256.149994  256.559998  256.559998   \n",
       "2017-10-25  256.179993  256.309998  254.000000  255.289993  255.289993   \n",
       "2017-10-26  255.990005  256.299988  255.479996  255.619995  255.619995   \n",
       "2017-10-27  256.470001  257.890015  255.630005  257.709991  257.709991   \n",
       "\n",
       "               volume  prior_close  direction  future_direction  \n",
       "Date                                                             \n",
       "2017-10-16   38221700   254.949997          1                 1  \n",
       "2017-10-17   31561000   255.289993          1                 1  \n",
       "2017-10-18   40888300   255.470001          1                 1  \n",
       "2017-10-19   61903800   255.720001          1                 1  \n",
       "2017-10-20   89176400   255.789993          1                 0  \n",
       "2017-10-23   63915300   257.109985          0                 1  \n",
       "2017-10-24   66935900   256.109985          1                 0  \n",
       "2017-10-25  103715300   256.559998          0                 1  \n",
       "2017-10-26   69798000   255.289993          1                 1  \n",
       "2017-10-27   85562500   255.619995          1                 0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy['prior_close'] = spy.close.shift(1)\n",
    "spy['direction'] = np.where(spy['close'] > spy['prior_close'], 1, 0)\n",
    "spy['future_direction'] = spy.direction.shift(-1)\n",
    "spy = spy.iloc[:-1]\n",
    "spy['future_direction'] = spy.future_direction.apply(int)\n",
    "spy.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample size by year varies in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>prior_close</th>\n",
       "      <th>direction</th>\n",
       "      <th>future_direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open  high  low  close  adjclose  volume  prior_close  direction  \\\n",
       "Date                                                                     \n",
       "2007   251   251  251    251       251     251          250        251   \n",
       "2008   253   253  253    253       253     253          253        253   \n",
       "2009   252   252  252    252       252     252          252        252   \n",
       "2010   252   252  252    252       252     252          252        252   \n",
       "2011   252   252  252    252       252     252          252        252   \n",
       "2012   250   250  250    250       250     250          250        250   \n",
       "2013   252   252  252    252       252     252          252        252   \n",
       "2014   252   252  252    252       252     252          252        252   \n",
       "2015   252   252  252    252       252     252          252        252   \n",
       "2016   252   252  252    252       252     252          252        252   \n",
       "2017   208   208  208    208       208     208          208        208   \n",
       "\n",
       "      future_direction  \n",
       "Date                    \n",
       "2007               251  \n",
       "2008               253  \n",
       "2009               252  \n",
       "2010               252  \n",
       "2011               252  \n",
       "2012               250  \n",
       "2013               252  \n",
       "2014               252  \n",
       "2015               252  \n",
       "2016               252  \n",
       "2017               208  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_samples = spy.groupby(spy.index.year).count()\n",
    "year_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation of the data set for training, testing and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take an 80% of the samples of each year to build a training set, a 10% of the samples of each year to build a testing set and finally another 10% to build the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_frac = 0.8\n",
    "testing_set_frac = 0.1\n",
    "validation_set_frac = 0.1\n",
    "\n",
    "training_set, testing_set, validation_set = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ith in range(len(year_samples)):\n",
    "    year = year_samples.index[ith]\n",
    "    set_size = year_samples.iloc[ith].close\n",
    "\n",
    "    training_size = int(set_size * training_set_frac)\n",
    "    testing_size = int(set_size * testing_set_frac)\n",
    "    validation_size = int(set_size * validation_set_frac)\n",
    "    \n",
    "    year_set = spy[spy.index.year == year]\n",
    "\n",
    "    training_set = training_set.append(year_set[:training_size])\n",
    "    testing_set = testing_set.append(year_set[training_size:training_size + testing_size + 1])\n",
    "    validation_set = validation_set.append(year_set[training_size + testing_size + 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of the first 80% of samples of each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>prior_close</th>\n",
       "      <th>direction</th>\n",
       "      <th>future_direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open  high  low  close  adjclose  volume  prior_close  direction  \\\n",
       "Date                                                                     \n",
       "2007   200   200  200    200       200     200          199        200   \n",
       "2008   202   202  202    202       202     202          202        202   \n",
       "2009   201   201  201    201       201     201          201        201   \n",
       "2010   201   201  201    201       201     201          201        201   \n",
       "2011   201   201  201    201       201     201          201        201   \n",
       "2012   200   200  200    200       200     200          200        200   \n",
       "2013   201   201  201    201       201     201          201        201   \n",
       "2014   201   201  201    201       201     201          201        201   \n",
       "2015   201   201  201    201       201     201          201        201   \n",
       "2016   201   201  201    201       201     201          201        201   \n",
       "2017   166   166  166    166       166     166          166        166   \n",
       "\n",
       "      future_direction  \n",
       "Date                    \n",
       "2007               200  \n",
       "2008               202  \n",
       "2009               201  \n",
       "2010               201  \n",
       "2011               201  \n",
       "2012               200  \n",
       "2013               201  \n",
       "2014               201  \n",
       "2015               201  \n",
       "2016               201  \n",
       "2017               166  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.groupby(training_set.index.year).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing set consists of 10% of samples of each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>prior_close</th>\n",
       "      <th>direction</th>\n",
       "      <th>future_direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open  high  low  close  adjclose  volume  prior_close  direction  \\\n",
       "Date                                                                     \n",
       "2007    26    26   26     26        26      26           26         26   \n",
       "2008    26    26   26     26        26      26           26         26   \n",
       "2009    26    26   26     26        26      26           26         26   \n",
       "2010    26    26   26     26        26      26           26         26   \n",
       "2011    26    26   26     26        26      26           26         26   \n",
       "2012    26    26   26     26        26      26           26         26   \n",
       "2013    26    26   26     26        26      26           26         26   \n",
       "2014    26    26   26     26        26      26           26         26   \n",
       "2015    26    26   26     26        26      26           26         26   \n",
       "2016    26    26   26     26        26      26           26         26   \n",
       "2017    21    21   21     21        21      21           21         21   \n",
       "\n",
       "      future_direction  \n",
       "Date                    \n",
       "2007                26  \n",
       "2008                26  \n",
       "2009                26  \n",
       "2010                26  \n",
       "2011                26  \n",
       "2012                26  \n",
       "2013                26  \n",
       "2014                26  \n",
       "2015                26  \n",
       "2016                26  \n",
       "2017                21  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set.groupby(testing_set.index.year).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the validation testing set consists of the last 10% of samples of each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>prior_close</th>\n",
       "      <th>direction</th>\n",
       "      <th>future_direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open  high  low  close  adjclose  volume  prior_close  direction  \\\n",
       "Date                                                                     \n",
       "2007    25    25   25     25        25      25           25         25   \n",
       "2008    25    25   25     25        25      25           25         25   \n",
       "2009    25    25   25     25        25      25           25         25   \n",
       "2010    25    25   25     25        25      25           25         25   \n",
       "2011    25    25   25     25        25      25           25         25   \n",
       "2012    24    24   24     24        24      24           24         24   \n",
       "2013    25    25   25     25        25      25           25         25   \n",
       "2014    25    25   25     25        25      25           25         25   \n",
       "2015    25    25   25     25        25      25           25         25   \n",
       "2016    25    25   25     25        25      25           25         25   \n",
       "2017    21    21   21     21        21      21           21         21   \n",
       "\n",
       "      future_direction  \n",
       "Date                    \n",
       "2007                25  \n",
       "2008                25  \n",
       "2009                25  \n",
       "2010                25  \n",
       "2011                25  \n",
       "2012                24  \n",
       "2013                25  \n",
       "2014                25  \n",
       "2015                25  \n",
       "2016                25  \n",
       "2017                21  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.groupby(validation_set.index.year).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of the indicators data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the network is computed data of 10 technical indicators:\n",
    "\n",
    "- SMA10\n",
    "- WMA10\n",
    "- Momentum\n",
    "- Stochastic K%\n",
    "- Stochastic D%\n",
    "- RSI\n",
    "- MACD\n",
    "- Larry William's R%\n",
    "- A/D Oscilator\n",
    "- CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ = spy.open.values\n",
    "high = spy.high.values\n",
    "low = spy.low.values\n",
    "close = spy.close.values\n",
    "volume = spy.close.values\n",
    "sample_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-27</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2017-10-23 00:00:00, 2017-10-24 00:00:00, 2017-10-25 00:00:00, 2017-10-26 00:00:00, 2017-10-27 00:00:00]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators = pd.DataFrame(index=spy.index)\n",
    "indicators.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['sma'] = talib.SMA(close, timeperiod=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['wma'] = talib.WMA(close, timeperiod=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['momentum'] = talib.MOM(close, timeperiod=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar configuración, este produce los dos valores %K y %D\n",
    "slowk, slowd = talib.STOCH(high, low, close, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "indicators['stochk'] = slowk\n",
    "indicators['stochd'] = slowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['rsi'] = talib.RSI(close, timeperiod=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        nan,         nan,         nan, ...,  1.71919997,\n",
       "        1.61562553,  1.68278911])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macd, macdsignal, macdhist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "indicators['macd'] = macd\n",
    "indicators['macdsig'] = macdsignal\n",
    "indicators['macdhist'] = macdhist\n",
    "macd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['williamsr'] = talib.WILLR(high, low, close, timeperiod=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['ad'] = talib.AD(high, low, close, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['cci'] = talib.CCI(high, low, close, timeperiod=sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is necessary to merge the indicators columns in to the splitted sets (training, testing, validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sma</th>\n",
       "      <th>wma</th>\n",
       "      <th>momentum</th>\n",
       "      <th>stochk</th>\n",
       "      <th>stochd</th>\n",
       "      <th>rsi</th>\n",
       "      <th>macd</th>\n",
       "      <th>macdsig</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>williamsr</th>\n",
       "      <th>ad</th>\n",
       "      <th>cci</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>255.471995</td>\n",
       "      <td>255.801811</td>\n",
       "      <td>2.159988</td>\n",
       "      <td>81.539607</td>\n",
       "      <td>87.806840</td>\n",
       "      <td>69.398467</td>\n",
       "      <td>1.883330</td>\n",
       "      <td>1.843897</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>-39.660608</td>\n",
       "      <td>56032.256499</td>\n",
       "      <td>138.654546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "      <td>255.665996</td>\n",
       "      <td>255.999630</td>\n",
       "      <td>1.940003</td>\n",
       "      <td>74.851831</td>\n",
       "      <td>82.615664</td>\n",
       "      <td>71.863007</td>\n",
       "      <td>1.859992</td>\n",
       "      <td>1.847116</td>\n",
       "      <td>0.012877</td>\n",
       "      <td>-29.780912</td>\n",
       "      <td>56085.083879</td>\n",
       "      <td>99.064502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-25</th>\n",
       "      <td>255.692994</td>\n",
       "      <td>255.931266</td>\n",
       "      <td>0.269989</td>\n",
       "      <td>54.127889</td>\n",
       "      <td>70.173109</td>\n",
       "      <td>57.373812</td>\n",
       "      <td>1.719200</td>\n",
       "      <td>1.821533</td>\n",
       "      <td>-0.102333</td>\n",
       "      <td>-63.248167</td>\n",
       "      <td>56114.921668</td>\n",
       "      <td>-46.220243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-26</th>\n",
       "      <td>255.790994</td>\n",
       "      <td>255.917993</td>\n",
       "      <td>0.979996</td>\n",
       "      <td>50.947257</td>\n",
       "      <td>59.975659</td>\n",
       "      <td>59.718643</td>\n",
       "      <td>1.615626</td>\n",
       "      <td>1.780351</td>\n",
       "      <td>-0.164726</td>\n",
       "      <td>-53.846428</td>\n",
       "      <td>55946.586778</td>\n",
       "      <td>9.343250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-27</th>\n",
       "      <td>256.066993</td>\n",
       "      <td>256.266902</td>\n",
       "      <td>2.759994</td>\n",
       "      <td>59.425852</td>\n",
       "      <td>54.833666</td>\n",
       "      <td>70.959988</td>\n",
       "      <td>1.682789</td>\n",
       "      <td>1.760839</td>\n",
       "      <td>-0.078050</td>\n",
       "      <td>-4.627848</td>\n",
       "      <td>56163.240328</td>\n",
       "      <td>124.155080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sma         wma  momentum     stochk     stochd        rsi  \\\n",
       "Date                                                                            \n",
       "2017-10-23  255.471995  255.801811  2.159988  81.539607  87.806840  69.398467   \n",
       "2017-10-24  255.665996  255.999630  1.940003  74.851831  82.615664  71.863007   \n",
       "2017-10-25  255.692994  255.931266  0.269989  54.127889  70.173109  57.373812   \n",
       "2017-10-26  255.790994  255.917993  0.979996  50.947257  59.975659  59.718643   \n",
       "2017-10-27  256.066993  256.266902  2.759994  59.425852  54.833666  70.959988   \n",
       "\n",
       "                macd   macdsig  macdhist  williamsr            ad         cci  \n",
       "Date                                                                           \n",
       "2017-10-23  1.883330  1.843897  0.039434 -39.660608  56032.256499  138.654546  \n",
       "2017-10-24  1.859992  1.847116  0.012877 -29.780912  56085.083879   99.064502  \n",
       "2017-10-25  1.719200  1.821533 -0.102333 -63.248167  56114.921668  -46.220243  \n",
       "2017-10-26  1.615626  1.780351 -0.164726 -53.846428  55946.586778    9.343250  \n",
       "2017-10-27  1.682789  1.760839 -0.078050  -4.627848  56163.240328  124.155080  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_set.join(indicators)\n",
    "testing_set = testing_set.join(indicators)\n",
    "validation_set = validation_set.join(indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>prior_close</th>\n",
       "      <th>direction</th>\n",
       "      <th>future_direction</th>\n",
       "      <th>sma</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum</th>\n",
       "      <th>stochk</th>\n",
       "      <th>stochd</th>\n",
       "      <th>rsi</th>\n",
       "      <th>macd</th>\n",
       "      <th>macdsig</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>williamsr</th>\n",
       "      <th>ad</th>\n",
       "      <th>cci</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-02-21</th>\n",
       "      <td>145.610001</td>\n",
       "      <td>146.070007</td>\n",
       "      <td>145.350006</td>\n",
       "      <td>145.979996</td>\n",
       "      <td>116.886948</td>\n",
       "      <td>63971600</td>\n",
       "      <td>146.039993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145.144000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089997</td>\n",
       "      <td>89.992783</td>\n",
       "      <td>91.767628</td>\n",
       "      <td>67.286692</td>\n",
       "      <td>1.023571</td>\n",
       "      <td>0.914752</td>\n",
       "      <td>0.108819</td>\n",
       "      <td>-7.309015</td>\n",
       "      <td>1437.598145</td>\n",
       "      <td>81.889256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-22</th>\n",
       "      <td>146.050003</td>\n",
       "      <td>146.419998</td>\n",
       "      <td>145.169998</td>\n",
       "      <td>145.869995</td>\n",
       "      <td>116.798935</td>\n",
       "      <td>79067400</td>\n",
       "      <td>145.979996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145.209999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659988</td>\n",
       "      <td>79.738918</td>\n",
       "      <td>87.692436</td>\n",
       "      <td>65.530479</td>\n",
       "      <td>1.014854</td>\n",
       "      <td>0.934773</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>-17.027978</td>\n",
       "      <td>1455.101844</td>\n",
       "      <td>68.911731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-23</th>\n",
       "      <td>145.740005</td>\n",
       "      <td>145.789993</td>\n",
       "      <td>145.029999</td>\n",
       "      <td>145.300003</td>\n",
       "      <td>116.342499</td>\n",
       "      <td>71966200</td>\n",
       "      <td>145.869995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145.237999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279999</td>\n",
       "      <td>55.633764</td>\n",
       "      <td>75.121822</td>\n",
       "      <td>56.969556</td>\n",
       "      <td>0.950990</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>-34.674811</td>\n",
       "      <td>1413.043661</td>\n",
       "      <td>20.721379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-26</th>\n",
       "      <td>145.830002</td>\n",
       "      <td>145.949997</td>\n",
       "      <td>144.750000</td>\n",
       "      <td>145.169998</td>\n",
       "      <td>116.238396</td>\n",
       "      <td>69192800</td>\n",
       "      <td>145.300003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145.360999</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229996</td>\n",
       "      <td>35.847984</td>\n",
       "      <td>57.073555</td>\n",
       "      <td>55.143882</td>\n",
       "      <td>0.879746</td>\n",
       "      <td>0.926362</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-38.699738</td>\n",
       "      <td>1369.492432</td>\n",
       "      <td>1.828678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-27</th>\n",
       "      <td>143.880005</td>\n",
       "      <td>144.199997</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>111.698410</td>\n",
       "      <td>274466500</td>\n",
       "      <td>145.169998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144.965999</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.949997</td>\n",
       "      <td>17.671720</td>\n",
       "      <td>36.384489</td>\n",
       "      <td>21.599962</td>\n",
       "      <td>0.361595</td>\n",
       "      <td>0.813409</td>\n",
       "      <td>-0.451814</td>\n",
       "      <td>-93.261454</td>\n",
       "      <td>1256.819371</td>\n",
       "      <td>-292.735006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "Date                                                                     \n",
       "2007-02-21  145.610001  146.070007  145.350006  145.979996  116.886948   \n",
       "2007-02-22  146.050003  146.419998  145.169998  145.869995  116.798935   \n",
       "2007-02-23  145.740005  145.789993  145.029999  145.300003  116.342499   \n",
       "2007-02-26  145.830002  145.949997  144.750000  145.169998  116.238396   \n",
       "2007-02-27  143.880005  144.199997  139.000000  139.500000  111.698410   \n",
       "\n",
       "               volume  prior_close  direction  future_direction         sma  \\\n",
       "Date                                                                          \n",
       "2007-02-21   63971600   146.039993          0                 0  145.144000   \n",
       "2007-02-22   79067400   145.979996          0                 0  145.209999   \n",
       "2007-02-23   71966200   145.869995          0                 0  145.237999   \n",
       "2007-02-26   69192800   145.300003          0                 0  145.360999   \n",
       "2007-02-27  274466500   145.169998          0                 1  144.965999   \n",
       "\n",
       "               ...      momentum     stochk     stochd        rsi      macd  \\\n",
       "Date           ...                                                            \n",
       "2007-02-21     ...      1.089997  89.992783  91.767628  67.286692  1.023571   \n",
       "2007-02-22     ...      0.659988  79.738918  87.692436  65.530479  1.014854   \n",
       "2007-02-23     ...      0.279999  55.633764  75.121822  56.969556  0.950990   \n",
       "2007-02-26     ...      1.229996  35.847984  57.073555  55.143882  0.879746   \n",
       "2007-02-27     ...     -3.949997  17.671720  36.384489  21.599962  0.361595   \n",
       "\n",
       "             macdsig  macdhist  williamsr           ad         cci  \n",
       "Date                                                                \n",
       "2007-02-21  0.914752  0.108819  -7.309015  1437.598145   81.889256  \n",
       "2007-02-22  0.934773  0.080082 -17.027978  1455.101844   68.911731  \n",
       "2007-02-23  0.938016  0.012974 -34.674811  1413.043661   20.721379  \n",
       "2007-02-26  0.926362 -0.046616 -38.699738  1369.492432    1.828678  \n",
       "2007-02-27  0.813409 -0.451814 -93.261454  1256.819371 -292.735006  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = training_set.iloc[33:]  # We discard first rows because some indicators don't have values\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (2142, 10) (2142,)\n",
      "Testing shape: (281, 10) (281,)\n",
      "Validation shape: (270, 10) (270,)\n"
     ]
    }
   ],
   "source": [
    "# macdsig y macdhist no estan en el paper pero igual se auto-calcularon (no se agregan)\n",
    "cols = ['sma', 'wma', 'momentum', 'stochk', 'stochd', 'rsi', 'macd', 'williamsr', 'ad', 'cci']\n",
    "\n",
    "Xtrain = training_set[cols].values\n",
    "Ytrain = training_set['future_direction'].values\n",
    "\n",
    "Xtest = testing_set[cols].values\n",
    "Ytest = testing_set['future_direction'].values\n",
    "\n",
    "Xval = validation_set[cols].values\n",
    "Yval = validation_set['future_direction'].values\n",
    "\n",
    "print('Training shape:', Xtrain.shape, Ytrain.shape)\n",
    "print('Testing shape:', Xtest.shape, Ytest.shape)\n",
    "print('Validation shape:', Xval.shape, Yval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data was scaled into the range of `[-1, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain_norm:\n",
      " [[-0.1604 -0.1529  0.4021  0.801   0.8725  0.5052  0.6364  0.8538 -0.9846\n",
      "   0.3832]\n",
      " [-0.1596 -0.1514  0.3841  0.5919  0.7867  0.4577  0.6348  0.6594 -0.9839\n",
      "   0.336 ]\n",
      " [-0.1593 -0.1512  0.3681  0.1004  0.522   0.226   0.6231  0.3065 -0.9856\n",
      "   0.1609]\n",
      " [-0.1579 -0.1513  0.408  -0.3031  0.1419  0.1766  0.6101  0.226  -0.9872\n",
      "   0.0922]\n",
      " [-0.1624 -0.1634  0.1908 -0.6738 -0.2938 -0.7309  0.5156 -0.8652 -0.9916\n",
      "  -0.9782]]\n",
      "Xtest_norm:\n",
      " [[-0.1458 -0.1389  0.1161 -0.5807 -0.5894 -0.1522  0.6403 -0.5165 -0.9941\n",
      "  -0.606 ]\n",
      " [-0.1533 -0.151  -0.2664 -0.6343 -0.6676 -0.682   0.5526 -0.9975 -1.\n",
      "  -0.7918]\n",
      " [-0.1587 -0.1599 -0.1553 -0.7142 -0.7113 -0.5205  0.4949 -0.5754 -0.9953\n",
      "  -0.8519]\n",
      " [-0.1644 -0.1651 -0.171  -0.6551 -0.7378 -0.3121  0.4667 -0.2998 -0.9907\n",
      "  -0.489 ]\n",
      " [-0.1702 -0.1699 -0.1723 -0.399  -0.6542 -0.3488  0.4398 -0.363  -0.9857\n",
      "  -0.4648]]\n",
      "Xval_norm:\n",
      " [[-0.2962 -0.3003 -0.51   -0.6721 -0.6988 -0.6768 -0.4367 -0.9428 -0.991\n",
      "  -0.3954]\n",
      " [-0.2975 -0.3045 -0.2328 -0.399  -0.5703 -0.4866 -0.4394 -0.5703 -0.9887\n",
      "  -0.2966]\n",
      " [-0.2986 -0.299  -0.2165 -0.093  -0.4377 -0.0584 -0.3341  0.4781 -0.9843\n",
      "   0.3298]\n",
      " [-0.2992 -0.2931 -0.1748  0.5112 -0.0225 -0.0543 -0.244   0.8463 -0.9824\n",
      "   0.4976]\n",
      " [-0.2956 -0.284   0.1522  0.8444  0.4138  0.0696 -0.1355  0.736  -0.9822\n",
      "   0.6011]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "Xtrain_norm = scaler.fit_transform(Xtrain)\n",
    "Xtest_norm = scaler.fit_transform(Xtest)\n",
    "Xval_norm = scaler.fit_transform(Xval)\n",
    "\n",
    "print('Xtrain_norm:\\n', Xtrain_norm[:5, :])\n",
    "print('Xtest_norm:\\n', Xtest_norm[:5, :])\n",
    "print('Xval_norm:\\n', Xval_norm[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute distribution of Y classes in the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 2142     | Y = 1: 1157 (54.01%)| Y = 0: 985 (45.99%)\n",
      "Test examples: 281       | Y = 1: 153 (54.45%) | Y = 0: 128 (45.55%)\n",
      "Validation examples: 270 | Y = 1: 153 (56.67%) | Y = 0: 117 (43.33%)\n",
      "Total observations: 2693\n"
     ]
    }
   ],
   "source": [
    "Ytrain1 = Ytrain.sum()\n",
    "Ytrain0 = len(Ytrain) - Ytrain1\n",
    "Ytrain1p = Ytrain1 / len(Ytrain) * 100\n",
    "Ytrain0p = Ytrain0 / len(Ytrain) * 100\n",
    "\n",
    "Ytest1 = Ytest.sum()\n",
    "Ytest0 = len(Ytest) - Ytest1\n",
    "Ytest1p = Ytest1 / len(Ytest) * 100\n",
    "Ytest0p = Ytest0 / len(Ytest) * 100\n",
    "\n",
    "Yval1 = Yval.sum()\n",
    "Yval0 = len(Yval) - Yval1\n",
    "Yval1p = Yval1 / len(Yval) * 100\n",
    "Yval0p = Yval0 / len(Yval) * 100\n",
    "\n",
    "print('Train examples: {}     | Y = 1: {} ({:.2f}%)| Y = 0: {} ({:.2f}%)'.format(len(Xtrain_norm), Ytrain1, Ytrain1p, Ytrain0, Ytrain0p))\n",
    "print('Test examples: {}       | Y = 1: {} ({:.2f}%) | Y = 0: {} ({:.2f}%)'.format(len(Xtest_norm), Ytest1, Ytest1p, Ytest0, Ytest0p))\n",
    "print('Validation examples: {} | Y = 1: {} ({:.2f}%) | Y = 0: {} ({:.2f}%)'.format(len(Xval_norm), Yval1, Yval1p, Yval0, Yval0p))\n",
    "print('Total observations:', len(Xtrain) + len(Xtest) + len(Xval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested parameters:\n",
    "- Number of neurons [10, 20, ..., 100]\n",
    "- Epochs (max_iter): [1000, 2000, 10000]\n",
    "- Momentum constant: [0.1, 0.2, ..., 0.9]\n",
    "- Learning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model (single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2.5, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=100, gamma=2.5)\n",
    "clf.fit(Xtrain_norm, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = clf.predict(Xtest_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 53.74%\n"
     ]
    }
   ],
   "source": [
    "print('Score: {:.2f}%'.format(clf.score(Xtest_norm, Ytest) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74, 54],\n",
       "       [76, 77]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "pr = confusion_matrix(Ytest, svm_predictions)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "- **True negatives** (_were 0 and predicted as 0_): **74**\n",
       "- **False negatives** (_were 1 but predicted them as 0_): **76**\n",
       "- **False positives** (_were 0 but predicted them as 1_): **54**\n",
       "- **True positives** (_were 1 and predicted as 1_): **77**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "true_negatives = pr[0][0]\n",
    "false_negatives = pr[1][0]\n",
    "false_positives = pr[0][1]\n",
    "true_positives = pr[1][1]\n",
    "\n",
    "Markdown(\"\"\"\n",
    "- **True negatives** (_were 0 and predicted as 0_): **{tn}**\n",
    "- **False negatives** (_were 1 but predicted them as 0_): **{fn}**\n",
    "- **False positives** (_were 0 but predicted them as 1_): **{fp}**\n",
    "- **True positives** (_were 1 and predicted as 1_): **{tp}**\n",
    "\"\"\".format(tn=true_negatives, fn=false_negatives, fp=false_positives, tp=true_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.58      0.53       128\n",
      "          1       0.59      0.50      0.54       153\n",
      "\n",
      "avg / total       0.54      0.54      0.54       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.4933,  0.5878]),\n",
       " array([ 0.5781,  0.5033]),\n",
       " array([ 0.5324,  0.5423]),\n",
       " array([128, 153]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = precision_recall_fscore_support(Ytest, svm_predictions)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.74%\n"
     ]
    }
   ],
   "source": [
    "correctly_predicted = true_positives + true_negatives\n",
    "badly_predicted = false_positives + false_negatives\n",
    "print('Accuracy: {:.2f}%'.format(correctly_predicted / (correctly_predicted + badly_predicted) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model (multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "\n",
    "gamma = np.linspace(0, 5, 51)\n",
    "c = np.array([1, 10, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "comparative = {}\n",
    "\n",
    "for params in product(gamma, c):\n",
    "    cgamma, cc = params\n",
    "    \n",
    "    clf.set_params(C=cc, gamma=cgamma)\n",
    "    clf.fit(Xtrain_norm, Ytrain)\n",
    "    comparative[params] = clf.score(Xtest_norm, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest score in the 153 parameter combinations: 45.91%\n",
      "Max score in the 153 parameter combinations: 57.65%\n"
     ]
    }
   ],
   "source": [
    "print('Lowest score in the 153 parameter combinations: {:.2f}%'.format(min(comparative.values()) * 100))\n",
    "print('Max score in the 153 parameter combinations: {:.2f}%'.format(max(comparative.values()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 2.8  |  C: 10  |  Score: 57.6512%\n",
      "Gamma: 2.9  |  C: 10  |  Score: 56.9395%\n",
      "Gamma: 3.0  |  C: 10  |  Score: 56.9395%\n",
      "Gamma: 3.7  |  C: 100  |  Score: 56.9395%\n",
      "Gamma: 2.7  |  C: 10  |  Score: 56.5836%\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "key_params = heapq.nlargest(5, comparative, key=comparative.get) # Get top 5 by best score\n",
    "\n",
    "for key in key_params:\n",
    "    print('Gamma: {:.1f}  |  C: {}  |  Score: {:.4f}%'.format(*key, comparative[key] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (Polynomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model (multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "\n",
    "degree = np.array([1, 2, 3, 4])\n",
    "gamma = np.linspace(0, 5, 51)\n",
    "c = np.array([1, 10, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-062a0604c21a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcomparative\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CIMAT/thesis/notebooks/.venv/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CIMAT/thesis/notebooks/.venv/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "comparative = {}\n",
    "\n",
    "for params in product(degree, gamma, c):\n",
    "    d, cgamma, cc = params\n",
    "    \n",
    "    clf.set_params(degree=d, C=cc, gamma=cgamma)\n",
    "    clf.fit(Xtrain_norm, Ytrain)\n",
    "    comparative[params] = clf.score(Xtest_norm, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lowest score in the 612 parameter combinations: {:.2f}%'.format(min(comparative.values()) * 100))\n",
    "print('Max score in the 612 parameter combinations: {:.2f}%'.format(max(comparative.values()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "key_params = heapq.nlargest(5, comparative, key=comparative.get) # Get top 5 by best score\n",
    "\n",
    "for key in key_params:\n",
    "    print('Degree: {} | Gamma: {:.1f}  |  C: {}  |  Score: {:.4f}%'.format(*key, comparative[key] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model (single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(30),\n",
    "    max_iter=5000,\n",
    "    momentum=0.7,\n",
    "    learning_rate_init=0.1,\n",
    "    activation='logistic')\n",
    "\n",
    "mlp.fit(Xtrain_norm, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(Xtest_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score: {:.2f}%'.format(mlp.score(Xtest_norm, Ytest) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "pr = confusion_matrix(Ytest, predictions)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "true_negatives = pr[0][0]\n",
    "false_negatives = pr[1][0]\n",
    "false_positives = pr[0][1]\n",
    "true_positives = pr[1][1]\n",
    "\n",
    "Markdown(\"\"\"\n",
    "- **True negatives** (_were 0 and predicted as 0_): **{tn}**\n",
    "- **False negatives** (_were 1 but predicted them as 0_): **{fn}**\n",
    "- **False positives** (_were 0 but predicted them as 1_): **{fp}**\n",
    "- **True positives** (_were 1 and predicted as 1_): **{tp}**\n",
    "\"\"\".format(tn=true_negatives, fn=false_negatives, fp=false_positives, tp=true_positives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _Precision = tp / (tp + fp)_: From all predicted values which ratio was actually well predicted.\n",
    "- _Recal = tp / (tp + fn)_: From all true values which ratio was actually well predicted.\n",
    "- _F1 score_: The higher the value the better use of the precision & recall tradeof.\n",
    "- _Support_: No. of observations of each class in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = precision_recall_fscore_support(Ytest, predictions)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_predicted = true_positives + true_negatives\n",
    "badly_predicted = false_positives + false_negatives\n",
    "print('Accuracy: {:.2f}%'.format(correctly_predicted / (correctly_predicted + badly_predicted) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training the model (multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(learning_rate_init=0.1, activation='logistic')\n",
    "\n",
    "epoch = np.linspace(1000, 10000, 10, dtype=int)\n",
    "neurons = np.linspace(10, 100, 10, dtype=int)\n",
    "momentum = np.linspace(.1, .9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "comparative = {}\n",
    "\n",
    "for params in product(epoch, neurons, momentum):\n",
    "    ep, n, mc = params\n",
    "    \n",
    "    mlp.set_params(max_iter=ep, hidden_layer_sizes=(n,), momentum=mc)\n",
    "    mlp.fit(Xtrain_norm, Ytrain)\n",
    "    comparative[params] = mlp.score(Xtest_norm, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lowest score in the 900 parameter combinations: {:.2f}%'.format(min(comparative.values()) * 100))\n",
    "print('Max score in the 900 parameter combinations: {:.2f}%'.format(max(comparative.values()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "key_params = heapq.nlargest(5, comparative, key=comparative.get) # Get top 5 by best score\n",
    "\n",
    "for key in key_params:\n",
    "    print('Epoch: {}  |  Neurons: {}  |  MC: {:.1f}  |  Score: {:.4f}%'.format(*key, comparative[key] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing performance in sets of best score parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating yearly scores for the best 1st set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep, n, mc = key_params[0]  # 1st set of best parameters\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    learning_rate_init=0.1,\n",
    "    activation='logistic',\n",
    "    max_iter=ep,\n",
    "    hidden_layer_sizes=(n,),\n",
    "    momentum=mc)\n",
    "\n",
    "mlp.fit(Xtrain_norm, Ytrain)\n",
    "Ypred_train = mlp.predict(Xtrain_norm)  # First analysis predicts same training set\n",
    "Ypred_test = mlp.predict(Xtest_norm)  # Second analysis predicts testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classification = pd.DataFrame({'Ytrain': Ytrain, 'Ypred_train': Ypred_train}, index=training_set.index)\n",
    "train_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification = pd.DataFrame({'Ytest': Ytest, 'Ypred_test': Ypred_test}, index=testing_set.index)\n",
    "test_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benchmark = train_classification['Ytrain'] == train_classification['Ypred_train']\n",
    "test_benchmark = test_classification['Ytest'] == test_classification['Ypred_test']\n",
    "\n",
    "train_score = train_benchmark.groupby(train_benchmark.index.year).apply(lambda s: s[s == True].count() / s.count()).rename('train_score')\n",
    "test_score = test_benchmark.groupby(test_benchmark.index.year).apply(lambda s: s[s == True].count() / s.count()).rename('test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_one = pd.concat([train_score, test_score], axis=1)\n",
    "benchmark_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train average: {}\\nTest average: {}'.format(\n",
    "    benchmark_one['train_score'].mean(),\n",
    "    benchmark_one['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating yearly scores for the best 2nd set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep, n, mc = key_params[1]  # 2nd set of best parameters\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    learning_rate_init=0.1,\n",
    "    activation='logistic',\n",
    "    max_iter=ep,\n",
    "    hidden_layer_sizes=(n,),\n",
    "    momentum=mc)\n",
    "\n",
    "mlp.fit(Xtrain_norm, Ytrain)\n",
    "Ypred_train = mlp.predict(Xtrain_norm)  # First analysis predicts same training set\n",
    "Ypred_test = mlp.predict(Xtest_norm)  # Second analysis predicts testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classification = pd.DataFrame({'Ytrain': Ytrain, 'Ypred_train': Ypred_train}, index=training_set.index)\n",
    "test_classification = pd.DataFrame({'Ytest': Ytest, 'Ypred_test': Ypred_test}, index=testing_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benchmark = train_classification['Ytrain'] == train_classification['Ypred_train']\n",
    "test_benchmark = test_classification['Ytest'] == test_classification['Ypred_test']\n",
    "\n",
    "train_score = train_benchmark.groupby(train_benchmark.index.year).apply(lambda s: s[s == True].count() / s.count()).rename('train_score')\n",
    "test_score = test_benchmark.groupby(test_benchmark.index.year).apply(lambda s: s[s == True].count() / s.count()).rename('test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_two = pd.concat([train_score, test_score], axis=1)\n",
    "benchmark_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train average: {}\\nTest average: {}'.format(\n",
    "    benchmark_two['train_score'].mean(),\n",
    "    benchmark_two['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating yearly scores for the best 3rd set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep, n, mc = key_params[2]  # 3rd set of best parameters\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    learning_rate_init=0.1,\n",
    "    activation='logistic',\n",
    "    max_iter=ep,\n",
    "    hidden_layer_sizes=(n,),\n",
    "    momentum=mc)\n",
    "\n",
    "mlp.fit(Xtrain_norm, Ytrain)\n",
    "Ypred_train = mlp.predict(Xtrain_norm)  # First analysis predicts same training set\n",
    "Ypred_test = mlp.predict(Xtest_norm)  # Second analysis predicts testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classification = pd.DataFrame({'Ytrain': Ytrain, 'Ypred_train': Ypred_train}, index=training_set.index)\n",
    "test_classification = pd.DataFrame({'Ytest': Ytest, 'Ypred_test': Ypred_test}, index=testing_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benchmark = train_classification['Ytrain'] == train_classification['Ypred_train']\n",
    "test_benchmark = test_classification['Ytest'] == test_classification['Ypred_test']\n",
    "\n",
    "train_score = train_benchmark.groupby(train_benchmark.index.year).apply(lambda s: s[s == True].count() / s.count()).rename('train_score')\n",
    "test_score = test_benchmark.groupby(test_benchmark.index.year).apply(lambda s: s[s == True].count() / s.count()).rename('test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_three = pd.concat([train_score, test_score], axis=1)\n",
    "benchmark_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train average: {:.2f}%\\nTest average: {:.2f}%'.format(\n",
    "    benchmark_three['train_score'].mean() * 100,\n",
    "    benchmark_three['test_score'].mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later: Also test various values of learning_rate, hidden_layers and activation function.\n",
    "# Later: train the network X times for each parameters to have statistical significance\n",
    "# Later: train the network with multiple market data to see how it behaves in other markets\n",
    "# Later: Backtest a strategy using the prediction results to get a set of trade results\n",
    "# Later: Analyze trade results with CDF and Montecarlo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
